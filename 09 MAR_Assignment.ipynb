{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67ba7892-8634-4c1a-a1d6-f4c1e1ebe3ab",
   "metadata": {},
   "source": [
    "## 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6adff11-39a1-4905-95dd-18ee56e4638c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08b41c0e-3cab-47bf-a04a-3d0f7397286e",
   "metadata": {},
   "source": [
    "Probability Mass Function (PMF):\n",
    "\n",
    "The Probability Mass Function (PMF) is used for discrete random variables. It assigns probabilities to each possible value that the random variable can take. In other words, the PMF gives the probability of observing a specific value. The PMF is defined as:\n",
    "\n",
    "PMF(x) = P(X = x)\n",
    "\n",
    "where X is the random variable and x represents a specific value.\n",
    "\n",
    "Example:\n",
    "\n",
    "Let's consider a fair six-sided die. The random variable X represents the outcome of a single roll. The PMF for this example would assign probabilities to each value of x (1, 2, 3, 4, 5, 6) based on the fact that the die is fair. Since each outcome has an equal chance of occurring, the PMF would be:\n",
    "\n",
    "PMF(x) = 1/6 for x = 1, 2, 3, 4, 5, 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6970b5d8-df28-41e0-a2a5-7391c6bb985a",
   "metadata": {},
   "source": [
    "Probability Density Function (PDF):\n",
    "\n",
    "The Probability Density Function (PDF) is used for continuous random variables. Unlike the PMF, which assigns probabilities to specific values, the PDF gives the relative likelihood of a random variable falling within a particular range of values. The area under the PDF curve within a given interval represents the probability of the random variable falling within that interval. The PDF is defined as:\n",
    "\n",
    "PDF(x) = dF(x)/dx\n",
    "\n",
    "where F(x) is the cumulative distribution function (CDF) of the random variable.\n",
    "\n",
    "Example:\n",
    "\n",
    "Consider the standard normal distribution, which has a bell-shaped curve. The random variable X represents a measurement from this distribution. The PDF for the standard normal distribution is given by:\n",
    "\n",
    "PDF(x) = (1/√(2π)) * e^(-x^2/2)\n",
    "\n",
    "This PDF describes the relative likelihood of different measurements falling within different ranges of values in the standard normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f7fdcd-f622-4d56-9682-55bbf918c20e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c2c44ea-d284-4b1c-bd4e-da0d95b8614e",
   "metadata": {},
   "source": [
    "## 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001ea365-ae63-4219-ad8d-7bd0777ae829",
   "metadata": {},
   "source": [
    "* The Cumulative Density Function (CDF):\n",
    "\n",
    "is a function that gives the probability that a random variable takes on a value less than or equal to a specified value. It provides a cumulative view of the probability distribution of a random variable.\n",
    "\n",
    "Mathematically, the CDF of a random variable X is denoted as F(x) and is defined as:\n",
    "\n",
    "F(x) = P(X ≤ x)\n",
    "\n",
    "In other words, the CDF gives the probability that the random variable X is less than or equal to a given value x.\n",
    "\n",
    "* Example:\n",
    "Let's consider a continuous random variable X that follows a standard normal distribution. The CDF of the standard normal distribution is denoted as Φ(x), and it gives the probability that X is less than or equal to a specified value x.\n",
    "\n",
    "For instance, if we want to find the probability that X is less than or equal to 1 in the standard normal distribution, we would calculate Φ(1). This value represents the area under the PDF curve to the left of x = 1.\n",
    "\n",
    "\n",
    "* CDF is used:\n",
    "\n",
    "The CDF is useful because it provides a comprehensive view of the probability distribution of a random variable. By evaluating the CDF at different points, we can determine probabilities associated with specific intervals or events. It allows us to calculate the probability of a random variable falling within a certain range, and also to calculate percentiles and quantiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53409c56-b808-49ce-9930-8ad704b29177",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a70282d-1d44-4096-bc11-f8c13303e441",
   "metadata": {},
   "source": [
    "## 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af70883-fb55-4029-80f5-e84def41380a",
   "metadata": {},
   "source": [
    "* The normal distribution, also known as the Gaussian distribution or bell curve, is commonly used as a model in various real-world situations. \n",
    "\n",
    "1. Heights:\n",
    "\n",
    "The heights of a large population tend to follow a normal distribution, with the majority of individuals clustered around the mean height.\n",
    "\n",
    "2. IQ Scores:\n",
    "\n",
    "IQ scores are often modeled using a normal distribution, with the mean set at 100 and a standard deviation of 15.\n",
    "\n",
    "3. Errors in Measurement:\n",
    "\n",
    "When measuring physical quantities, such as length, weight, or time, measurement errors often follow a normal distribution.\n",
    "\n",
    "4. Test Scores:\n",
    "\n",
    "In standardized testing, test scores are often assumed to be normally distributed, allowing for the determination of percentiles and the comparison of performance.\n",
    "\n",
    "* The normal distribution is characterized by two parameters: the mean (μ) and the standard deviation (σ). The mean represents the central tendency or average value of the distribution, while the standard deviation determines the spread or variability of the data points around the mean.\n",
    "\n",
    "\n",
    "* Some Explain how the parameters of the normal distribution relate to the shape of the distribution.\n",
    "\n",
    "* The mean (μ) defines the location of the peak or center of the normal distribution. Shifting the mean to the left or right will change the position of the peak accordingly.\n",
    "\n",
    "* The standard deviation (σ) controls the width of the distribution. A smaller standard deviation results in a narrower distribution, with the data points concentrated closely around the mean. Conversely, a larger standard deviation leads to a wider distribution, with the data points spread out more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b7f73b-c35f-4790-ae36-1b8502b69a9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69fe5bbf-9917-4a5a-97a7-08fa471f46c4",
   "metadata": {},
   "source": [
    "## 4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af830a61-8b0f-44af-ba8f-f22f426cd309",
   "metadata": {},
   "source": [
    "The normal distribution, also known as the Gaussian distribution or bell curve, holds great importance in various fields due to its mathematical properties and its ability to approximate many natural phenomena. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6827e5d7-6b86-4a14-8f7a-e1d3757f10e0",
   "metadata": {},
   "source": [
    "importance of the normal distribution are:\n",
    "    \n",
    "    * Central Limit Theorem: \n",
    "    The normal distribution is closely related to the Central Limit Theorem, which states that the sum or average of a large number of independent and identically distributed random variables will follow a normal distribution, regardless of the original distribution of the variables.\n",
    "    \n",
    "    \n",
    "    * Statistical Inference:\n",
    "    Many statistical methods and techniques are based on the assumption of a normal distribution. Parameters estimation, hypothesis testing, and confidence intervals often rely on the assumption of normality. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bae579-cd4a-40e4-b008-8f69227efdba",
   "metadata": {},
   "source": [
    "* Real-life examples of phenomena that can be approximated by a normal distribution include:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70214c86-a452-4394-b05b-e8fdec53fd42",
   "metadata": {},
   "source": [
    "1. Heights of a Population:\n",
    "\n",
    "The heights of individuals in a large population tend to follow a normal distribution, with the majority of heights clustering around the mean height.\n",
    "\n",
    "2. IQ Scores:\n",
    "\n",
    "IQ scores are often assumed to be normally distributed, with a mean of 100 and a standard deviation of 15. This assumption allows for the calculation of percentiles, comparison of performance, and identification of exceptional scores.\n",
    "\n",
    "3. Errors in Measurement:\n",
    "\n",
    "In many scientific experiments and measurements, the errors or residuals tend to follow a normal distribution. This assumption allows for the estimation of uncertainty and the evaluation of statistical significance.\n",
    "\n",
    "4. Test Scores:\n",
    "\n",
    "Standardized tests, such as the SAT or GRE, are designed and scored to follow a normal distribution. This enables the establishment of percentile ranks and the comparison of performance among test-takers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9227679e-f39c-4c13-b956-0fd974c616d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd6f0a9f-d61c-4d8e-9839-5d7fb1c8f15e",
   "metadata": {},
   "source": [
    "## 5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c58012c-82ae-4203-85d2-6fa5558e43cd",
   "metadata": {},
   "source": [
    "* The Bernoulli distribution is a discrete probability distribution that models a single experiment with two possible outcomes: success (typically denoted as 1) or failure (typically denoted as 0). It is named after Jacob Bernoulli, a Swiss mathematician who introduced the concept.\n",
    "\n",
    "\n",
    "The probability mass function (PMF) of the Bernoulli distribution is given by:\n",
    "\n",
    "P(x) = p^x * (1-p)^(1-x)\n",
    "\n",
    "where:\n",
    "\n",
    "P(x) is the probability of observing outcome x,\n",
    "p is the probability of success (1) in a single trial,\n",
    "x can take values 0 (failure) or 1 (success).\n",
    "\n",
    "\n",
    "* Example:\n",
    "Consider flipping a fair coin. The Bernoulli distribution can be used to model the outcome of a single flip. Let's assume that heads represent success (1) and tails represent failure (0). In this case, the probability of heads (success) is p = 0.5, and the probability of tails (failure) is 1-p = 0.5. The Bernoulli distribution for this example would be:\n",
    "\n",
    "P(0) = (0.5)^0 * (1-0.5)^(1-0) = 0.5\n",
    "P(1) = (0.5)^1 * (1-0.5)^(1-1) = 0.5\n",
    "\n",
    "This means that the probability of observing a success (heads) is 0.5, and the probability of observing a failure (tails) is also 0.5.\n",
    "\n",
    "\n",
    "Difference between Bernoulli Distribution and Binomial Distribution:\n",
    "\n",
    "1.  Number of Trials:\n",
    "\n",
    "The Bernoulli distribution models a single trial or experiment with two possible outcomes (success or failure). In contrast, the binomial distribution models multiple independent and identical Bernoulli trials. It represents the number of successes in a fixed number of trials.\n",
    "\n",
    "2. Number of Possible Outcomes:\n",
    "\n",
    "The Bernoulli distribution has only two possible outcomes (0 or 1), representing success or failure. The binomial distribution, on the other hand, can have a range of possible outcomes, from 0 to the number of trials.\n",
    "\n",
    "3. Parameters:\n",
    "\n",
    "The Bernoulli distribution has a single parameter, p, representing the probability of success in a single trial. The binomial distribution has two parameters, n and p, where n represents the number of trials and p represents the probability of success in each trial.\n",
    "\n",
    "4. Probability Mass Function (PMF):\n",
    "\n",
    "The PMF of the Bernoulli distribution calculates the probability of a single outcome (either 0 or 1). The PMF of the binomial distribution calculates the probability of obtaining a specific number of successes (k) in a fixed number of trials (n)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d35add4-c25e-4877-9aea-7f8706cdce96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5323e7c8-c615-4cc5-9147-e0330b2c9fa6",
   "metadata": {},
   "source": [
    "## 6."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb8c9e9-b45d-4df7-871e-c99062b52501",
   "metadata": {},
   "source": [
    "To calculate the probability that a randomly selected observation from a normally distributed dataset with a mean of 50 and a standard deviation of 10 will be greater than 60, we can use the standard normal distribution and the z-score.\n",
    "\n",
    "The z-score measures the number of standard deviations a data point is away from the mean. It is calculated as:\n",
    "\n",
    "z = (x - μ) / σ\n",
    "\n",
    "Where:\n",
    "\n",
    "* x is the value we want to find the probability for (60 in this case),\n",
    "* μ is the mean of the dataset (50),\n",
    "* σ is the standard deviation of the dataset (10).\n",
    "In our case:\n",
    "z = (60 - 50) / 10 = 1\n",
    "\n",
    "To find the probability corresponding to this z-score, we can refer to the standard normal distribution table or use statistical software.\n",
    "\n",
    "The probability that a randomly selected observation will be greater than 60 can be calculated as the area under the standard normal curve to the right of the z-score of 1. In other words, we need to find P(Z > 1).\n",
    "\n",
    "From the standard normal distribution table, we can find that P(Z > 1) is approximately 0.1587.\n",
    "\n",
    "Therefore, the probability that a randomly selected observation will be greater than 60 is approximately 0.1587 or 15.87%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41d4d28-a119-4003-b94d-3c050de7d4d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f977b8a9-daa5-468b-89d5-95fe839a7eab",
   "metadata": {},
   "source": [
    "## 7."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d58ac99-aba3-4e04-afe9-cf4677e74079",
   "metadata": {},
   "source": [
    "The uniform distribution is a continuous probability distribution that models a situation where all outcomes within a given range are equally likely. It is characterized by a constant probability density function (PDF) over the specified range.\n",
    "\n",
    "* Example:\n",
    "\n",
    "Consider a fair six-sided die. The outcome of rolling the die can be modeled using a uniform distribution. The range of possible outcomes is from 1 to 6, and each outcome has an equal probability of occurring.\n",
    "\n",
    "In this case, the probability density function (PDF) of the uniform distribution can be expressed as:\n",
    "\n",
    "f(x) = 1 / (b - a)\n",
    "\n",
    "where:\n",
    "\n",
    "* f(x) is the probability density function at a given value x,\n",
    "* a is the lower limit of the range (1 in this example),\n",
    "* b is the upper limit of the range (6 in this example).\n",
    "For the fair six-sided die, the probability of rolling any specific number (1, 2, 3, 4, 5, or 6) is equal to 1/6, as each outcome has an equal chance of occurring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25864db1-46c6-4539-8060-e39d23e14b03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7fdde8a-03ad-4d9f-9384-071c473c44f6",
   "metadata": {},
   "source": [
    "## 9."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e300e8-5d9f-4b18-93aa-d2c9de20dc72",
   "metadata": {},
   "source": [
    "The z-score, also known as the standard score, is a statistical measurement that quantifies the distance between a data point and the mean of a dataset in terms of standard deviations. \n",
    "\n",
    "* The formula for calculating the z-score of a data point, given the mean (μ) and standard deviation (σ) of the dataset, is:\n",
    "\n",
    "z = (x - μ) / σ\n",
    "\n",
    "Where:\n",
    "\n",
    "z is the z-score\n",
    "x is the individual data point\n",
    "μ is the mean of the dataset\n",
    "σ is the standard deviation of the dataset\n",
    "\n",
    "* The importance of the z-score:\n",
    "\n",
    "1. Standardization:\n",
    "\n",
    "By converting raw data into z-scores, we transform the data to have a mean of zero and a standard deviation of one. This standardization allows for easier comparison and analysis of different variables with varying scales and distributions.\n",
    "\n",
    "2. Relative Position:\n",
    "\n",
    "The z-score provides information about the relative position of a data point within a dataset. \n",
    "\n",
    "3. Probability and Percentiles: \n",
    "\n",
    "The z-score can be used to calculate probabilities and determine percentiles.\n",
    "\n",
    "4. Outlier Detection:\n",
    "\n",
    "Z-scores can be employed to identify outliers in a dataset.\n",
    "\n",
    "5. Data Comparison:\n",
    "\n",
    "The z-score allows for meaningful comparisons between data points from different datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de4d164-d280-40ca-9123-2177587a27d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce086459-fd11-4d8d-a4c0-d609a7f09aa7",
   "metadata": {},
   "source": [
    "## 9. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa4b5b5-fd28-4609-a78d-29b85f159019",
   "metadata": {},
   "source": [
    "* \n",
    "The Central Limit Theorem (CLT) is a fundamental concept in statistics that describes the behavior of the sampling distribution of the mean for a sufficiently large sample size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e195aed5-74f8-4466-978a-af0a489808b0",
   "metadata": {},
   "source": [
    "The significance of the Central Limit Theorem is:\n",
    "\n",
    "1. Sampling Distribution:\n",
    "\n",
    "The Central Limit Theorem allows us to make inferences about the population mean based on the distribution of sample means. It states that regardless of the population distribution, the sampling distribution of the mean will tend to be approximately normal. This is crucial because it enables us to use the properties of the normal distribution for making statistical inferences.\n",
    "\n",
    "2. Population Estimation:\n",
    "\n",
    "The Central Limit Theorem facilitates the estimation of population parameters, particularly the population mean.\n",
    "\n",
    "3. Hypothesis Testing:\n",
    "\n",
    "The Central Limit Theorem is the basis for many statistical tests, such as the z-test and t-test. These tests rely on the assumption of normality, which is satisfied by the Central Limit Theorem when the sample size is sufficiently large.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dcfe8d-4c1b-4695-b7c5-bc7cb8e7da1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01aeca92-5a61-4561-a8c0-4172a4124000",
   "metadata": {},
   "source": [
    "## 10."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a439e78-db20-41de-8374-6a86b2b128ed",
   "metadata": {},
   "source": [
    "* The Central Limit Theorem (CLT) relies on certain assumptions to hold true. These assumptions include:\n",
    "\n",
    "1. Random Sampling:\n",
    "\n",
    "The samples taken from the population should be selected randomly and independently. Each observation in the sample should be unrelated to the others, and the sampling process should not introduce any systematic bias.\n",
    "\n",
    "2. Finite Variance:\n",
    "\n",
    "The population from which the samples are drawn should have a finite variance (σ^2). This assumption ensures that the population's variability is well-defined and not extremely large.\n",
    "\n",
    "3. Independence:\n",
    "\n",
    "The observations within each sample should be independent of each other. This means that the value of one observation should not influence or be influenced by the values of other observations in the sample.\n",
    "\n",
    "4. Sample Size:\n",
    "\n",
    "The Central Limit Theorem is most reliable and accurate when the sample size is sufficiently large. While there is no exact threshold, a commonly used guideline is that the sample size should be at least 30. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0972b9-4577-48da-9e63-9307c1ccfbab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
