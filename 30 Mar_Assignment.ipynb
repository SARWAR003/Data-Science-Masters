{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e20a649",
   "metadata": {},
   "source": [
    "## 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be750c4f",
   "metadata": {},
   "source": [
    "* Elastic Net Regression is a regression technique that combines both Ridge Regression and Lasso Regression. It is used to handle high-dimensional data where there are potentially many features or variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b15872",
   "metadata": {},
   "source": [
    "1. Ridge Regression:\n",
    "\n",
    "Ridge Regression introduces a penalty term (L2 regularization) to the linear regression equation, which shrinks the coefficients of less important variables towards zero. However, Ridge Regression does not perform variable selection, meaning it will include all the features in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a800cd54",
   "metadata": {},
   "source": [
    "2. Lasso Regression:\n",
    "\n",
    "Lasso Regression also introduces a penalty term (L1 regularization) to the linear regression equation. It not only shrinks the coefficients but also performs variable selection by forcing some coefficients to become exactly zero. This makes Lasso Regression useful for feature selection. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405c5de3",
   "metadata": {},
   "source": [
    "3. Elastic Net Regression:\n",
    "\n",
    "Elastic Net Regression combines both Ridge and Lasso regularization techniques. It adds both the L1 and L2 penalty terms to the linear regression equation. The L1 penalty encourages sparsity and feature selection, while the L2 penalty helps to overcome the issue of correlated features. Elastic Net Regression finds a balance between Ridge and Lasso and is particularly effective when there are many correlated variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8690d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d84204a3",
   "metadata": {},
   "source": [
    "## 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59aed280",
   "metadata": {},
   "source": [
    "* To choose the optimal values of the regularization parameters for Elastic Net Regression, you typically use techniques such as cross-validation. The two main parameters for Elastic Net Regression are the alpha parameter and the l1_ratio parameter.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b0d7c2",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "* To choose the optimal values for these parameters, you can follow these steps:\n",
    "\n",
    "1. Grid Search:\n",
    "\n",
    "Start by defining a grid of possible values for alpha and l1_ratio. For each combination of values, train an Elastic Net Regression model on your training data.\n",
    "\n",
    "2. Cross-Validation:\n",
    "\n",
    "Use cross-validation techniques such as k-fold cross-validation to evaluate the performance of the model for each combination of parameter values. \n",
    "\n",
    "3. Performance Metric:\n",
    "\n",
    "Choose an appropriate performance metric to evaluate the models, such as mean squared error (MSE), mean absolute error (MAE), or R-squared. Select the combination of parameter values that results in the best performance metric.\n",
    "\n",
    "4. Final Model Selection: \n",
    "\n",
    "Once you have identified the optimal parameter values, train a final Elastic Net Regression model using the entire training dataset with those values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51e2aca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55e0f4a2",
   "metadata": {},
   "source": [
    "## 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c2ce8b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Advantages:\n",
    "1. Handles multicollinearity: \n",
    "\n",
    "Elastic Net Regression is effective in handling multicollinearity, which is when predictor variables are highly correlated. The combined L1 and L2 penalties help to select relevant features and reduce the impact of multicollinearity.\n",
    "\n",
    "2. Feature selection:\n",
    "\n",
    "Elastic Net Regression can perform automatic feature selection by shrinking some coefficients to zero. \n",
    "\n",
    "3. Balances L1 and L2 penalties:\n",
    "\n",
    "The L1 penalty in Elastic Net encourages sparsity, while the L2 penalty encourages shrinkage. \n",
    "\n",
    "4. Works well with high-dimensional data:\n",
    "\n",
    "Elastic Net Regression performs well in situations where the number of predictors is large compared to the number of observations. It can handle high-dimensional datasets effectively.\n",
    "\n",
    "Disadvantages:\n",
    "\n",
    "1. Interpretability:\n",
    "\n",
    "While Elastic Net Regression provides some level of feature selection, it may be less interpretable compared to simpler regression models like linear regression. The combination of L1 and L2 penalties can make it challenging to interpret individual coefficients.\n",
    "\n",
    "2. Parameter tuning:\n",
    "\n",
    "Elastic Net Regression has two regularization parameters (alpha and l1_ratio) that need to be tuned. Finding the optimal values for these parameters can be time-consuming and computationally expensive, especially when using grid search or cross-validation.\n",
    "\n",
    "3. Dependency on feature scaling:\n",
    "\n",
    "Elastic Net Regression is sensitive to the scale of predictor variables. It is recommended to scale the features before fitting the model to ensure that all variables are on a similar scale. \n",
    "4. Limited use for non-linear relationships:\n",
    "\n",
    "Elastic Net Regression assumes a linear relationship between predictors and the target variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c23cea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c66ce230",
   "metadata": {},
   "source": [
    "## 4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d9da18",
   "metadata": {},
   "source": [
    "\n",
    "1. Predictive modeling:\n",
    "\n",
    "Elastic Net Regression is commonly used for predictive modeling tasks, such as predicting sales, customer churn, stock prices, or housing prices. Its ability to handle high-dimensional data and perform feature selection makes it valuable for building accurate predictive models.\n",
    "\n",
    "2. Feature selection:\n",
    "\n",
    "Elastic Net Regression's ability to automatically perform feature selection by shrinking coefficients to zero makes it useful for identifying the most important predictors in a dataset. This can be beneficial when dealing with datasets with a large number of features and selecting the most relevant variables.\n",
    "\n",
    "3. Genomics and bioinformatics:\n",
    "\n",
    "Elastic Net Regression is widely used in genomics and bioinformatics research for analyzing gene expression data and identifying relevant biomarkers. Its ability to handle high-dimensional data and mitigate multicollinearity is particularly useful in these fields.\n",
    "\n",
    "4. Financial modeling: \n",
    "\n",
    "Elastic Net Regression can be applied to financial modeling tasks, such as predicting stock market returns, credit risk assessment, portfolio optimization, and asset pricing. Its ability to handle multicollinearity and feature selection can improve the accuracy and interpretability of financial models.\n",
    "\n",
    "5. Healthcare and medical research:\n",
    "\n",
    "Elastic Net Regression is used in healthcare and medical research for various applications, including disease prediction, diagnostic modeling, treatment response prediction, and identifying risk factors. It can help uncover significant predictors and understand the relationships between variables in medical datasets.\n",
    "\n",
    "6. Marketing and customer analytics:\n",
    "\n",
    "Elastic Net Regression is valuable in marketing and customer analytics for tasks like customer segmentation, customer lifetime value prediction, demand forecasting, and recommendation systems. It can help identify key drivers and patterns in customer behavior.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da59940f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c4513755",
   "metadata": {},
   "source": [
    "## 5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eacf406",
   "metadata": {},
   "source": [
    "Interpreting the coefficients in Elastic Net Regression is similar to interpreting coefficients in other linear regression models. However, due to the regularization in Elastic Net Regression, the interpretation can be slightly different. Here's how you can interpret the coefficients in Elastic Net Regression:\n",
    "\n",
    "1. Magnitude:\n",
    "\n",
    "The magnitude of the coefficient represents the strength of the relationship between the predictor variable and the target variable. A larger magnitude indicates a stronger impact on the target variable, while a smaller magnitude indicates a weaker impact.\n",
    "\n",
    "2. Sign:\n",
    "\n",
    "The sign of the coefficient (+ or -) indicates the direction of the relationship between the predictor variable and the target variable. A positive coefficient suggests a positive relationship, meaning an increase in the predictor variable is associated with an increase in the target variable. \n",
    "\n",
    "3. Variable selection: \n",
    "\n",
    "In Elastic Net Regression, the coefficients can be shrunk towards zero due to the regularization. A coefficient of zero indicates that the corresponding predictor variable has been effectively excluded from the model and has no impact on the target variable. \n",
    "\n",
    "4. Relative magnitude:\n",
    "When comparing the magnitudes of coefficients, it's important to consider the scale of the predictor variables. Variables with larger scales may have larger coefficients simply due to their scale, not necessarily indicating a stronger relationship with the target variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948a5503",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3161ffda",
   "metadata": {},
   "source": [
    "## 6."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fd1139",
   "metadata": {},
   "source": [
    "Handling missing values in Elastic Net Regression requires careful consideration, as missing data can affect the accuracy and reliability of the model. Here are a few approaches to handle missing values in Elastic Net Regression:\n",
    "\n",
    "1. Dropping missing values:\n",
    "\n",
    "One straightforward approach is to remove the observations with missing values from the dataset. However, this approach can result in a loss of valuable data if the missing values are not randomly distributed. \n",
    "\n",
    "2. Imputation:\n",
    "\n",
    "Another common approach is to fill in the missing values with estimated values. Imputation methods can include mean imputation, median imputation, mode imputation, or more advanced techniques like regression imputation or k-nearest neighbors imputation. \n",
    "\n",
    "3. Indicator variable: \n",
    "\n",
    "For categorical variables, you can create an additional indicator variable to capture the missingness. This approach treats the missing values as a separate category and allows the model to learn the relationship between the missingness and the target variable.\n",
    "\n",
    "4. Advanced imputation techniques:\n",
    "\n",
    "There are more sophisticated imputation techniques available, such as multiple imputation or using machine learning algorithms like random forests or XGBoost to predict missing values based on other variables in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2325ce99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "685c4bb4",
   "metadata": {},
   "source": [
    " ## 7."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18459d9",
   "metadata": {},
   "source": [
    "Elastic Net Regression can be effectively used for feature selection by leveraging its inherent regularization properties. The L1 regularization term in Elastic Net encourages sparsity in the coefficient estimates, resulting in automatic feature selection. Here's a step-by-step approach to using Elastic Net Regression for feature selection:\n",
    "\n",
    "1. Standardize the features:\n",
    "\n",
    "It is important to standardize the features before applying Elastic Net Regression to ensure that they are on a similar scale. This helps in comparing the magnitudes of the coefficients and avoids giving undue importance to variables with larger scales.\n",
    "\n",
    "2. Split the data:\n",
    "\n",
    "Divide your dataset into training and testing sets. The training set will be used to fit the Elastic Net Regression model, and the testing set will be used to evaluate the performance and generalization of the selected features.\n",
    "\n",
    "3. Perform feature selection:\n",
    "\n",
    "Fit the Elastic Net Regression model on the training set. The regularization parameters, alpha and l1_ratio, need to be chosen appropriately. The alpha parameter controls the overall strength of regularization, while the l1_ratio parameter determines the mix between L1 and L2 regularization. \n",
    "\n",
    "4. Examine the coefficients:\n",
    "\n",
    "Once the model is fitted, examine the estimated coefficients. The coefficients associated with features that have non-zero values indicate their importance in the model. Features with non-zero coefficients are considered selected features.\n",
    "\n",
    "5. Evaluate performance: \n",
    "\n",
    "Use the testing set to evaluate the performance of the selected features. Calculate appropriate evaluation metrics, such as mean squared error (MSE) or R-squared, to assess the predictive performance of the model using only the selected features.\n",
    "\n",
    "6. Refine the feature selection:\n",
    "\n",
    "If necessary, you can fine-tune the feature selection process by adjusting the regularization parameters or applying additional techniques like stepwise regression or recursive feature elimination to further optimize the subset of selected features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e4eb1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "630c9ea8",
   "metadata": {},
   "source": [
    "## 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8e0d9a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2a183721",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4f5dc047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a random regression dataset\n",
    "X, y = make_regression(n_samples=100, n_features=10, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "218e85a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "112b92f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ElasticNet(alpha=0.5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ElasticNet</label><div class=\"sk-toggleable__content\"><pre>ElasticNet(alpha=0.5)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "ElasticNet(alpha=0.5)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Train an Elastic Net Regression model\n",
    "model = ElasticNet(alpha=0.5, l1_ratio=0.5)\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9b31132f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pickle the trained model\n",
    "with open('elastic_net_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "43ca1b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the saved model\n",
    "with open('elastic_net_model.pkl', 'rb') as f:\n",
    "    loaded_model = pickle.load(f)\n",
    "\n",
    "# Use the loaded model for predictions or other tasks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e0e437",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fcf208d3",
   "metadata": {},
   "source": [
    "## 9."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5b3c71",
   "metadata": {},
   "source": [
    "The purpose of pickling a model in machine learning is to save the trained model object to a file. Pickling is the process of serializing the model object into a binary format that can be stored or transmitted. This allows you to save the model's parameters, state, and trained weights so that you can reuse it later without retraining.\n",
    "\n",
    "There are several reasons why pickling a model is useful:\n",
    "\n",
    "1. **Persistence**:\n",
    "\n",
    "Pickling allows you to save the trained model to disk and load it back at a later time. This is beneficial when you want to use the model for prediction on new data or deploy it in a production environment.\n",
    "\n",
    "2. **Sharing**:\n",
    "\n",
    "Pickling enables you to share the trained model with others, such as team members or collaborators, who can then use the model without having to retrain it.\n",
    "\n",
    "3. **Scalability**:\n",
    "\n",
    "Pickling allows you to train a model on a powerful machine or cluster and then transfer the serialized model to a different machine for deployment or inference tasks.\n",
    "\n",
    "4. **State preservation**:\n",
    "\n",
    "Pickling preserves the state of the trained model, including the learned parameters and any preprocessing steps. This ensures consistency when using the model for prediction on new data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f955c704",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9836c5fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83858e2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae560ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bd0679",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70324cf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f7b4ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a235fa49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98407cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27278f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd852acd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
